Project 

Table of Contents

    Project 01: Automating System Monitoring and Reporting with Shell Scripting
        
        
    Project 02: Deploying a Multi-Tier Application with a CI/CD Pipeline
       
        

Project 01: Automating System Monitoring and Reporting with Shell Scripting
Overview

Develop an advanced shell script for system operations to automate the monitoring of system metrics and generate detailed reports. The script will utilize Linux shell scripting to monitor system performance, analyze logs, and provide actionable insights for system administrators.
Step-by-Step Guide
1. Script Initialization

    Initialize the script with necessary variables and configurations.
    Ensure required commands and utilities are available.

2. System Metrics Collection

    Monitor CPU usage, memory utilization, disk space, and network statistics.

sh

CPU_USAGE=$(top -bn1 | grep "Cpu(s)" | sed "s/.*, *\([0-9.]*\)%* id.*/\1/" | awk '{print 100 - $1}')
DISK_USAGE=$(df -h | awk '$NF=="/"{printf "%s", $5}')
MEMORY_USAGE=$(free | grep Mem | awk '{print $3/$2 * 100.0}')

    Capture information on top resource-consuming processes.

3. Log Analysis

    Parse system logs (e.g., syslog) for critical events and errors.

sh

CRITICAL_LOGS=$(tail -n 200 /var/log/syslog | grep -iE 'error|critical')

    Generate summaries of recent log entries based on severity.

sh

RECENT_LOGS=$(tail -n 20 /var/log/syslog)

4. Health Checks

    Check the status of essential services (e.g., Nginx, MySQL).

sh

systemctl status nginx

    Verify connectivity to external services or databases.

5. Alerting Mechanism

    Implement thresholds for critical metrics (CPU, memory) triggering alerts.
    Send email notifications to sysadmins with critical alerts.

6. Report Generation

    Compile all collected data into a detailed report.
    Include graphs or visual representations where applicable.

7. Automation and Scheduling

    Configure the script to run periodically via cron for automated monitoring.

sh

crontab -e

Add the following line to run the script every hour:

sh

0 * * * * /path/to/system_ops.sh

    Ensure the script can handle both interactive and non-interactive execution modes.

8. User Interaction

    Provide options for interactive mode to allow sysadmins to manually trigger checks or view specific metrics.
    Ensure the script is user-friendly with clear prompts and outputs.

9. Documentation

    Create a README file detailing script usage, prerequisites, and customization options.
    Include examples of typical outputs and how to interpret them.

Solution
Create the Script File

sh

nano system_monitor.sh

Add the Following Code to system_monitor.sh

sh

#!/bin/bash

REPORTDIR="/path/to/reports/"
ALERT_THRESHOLD_CPU=75
ALERT_THRESHOLD_MEM=40
SERVICE_STATUS=("nginx" "mysql")
EXTERNAL_SERVICES=("google.com" "mysql://db.test.com")

# Function to collect system metrics
System_Metrics() {
    echo -e "\nCPU Usage: "
    top -bn1 | grep "Cpu(s)" | sed "s/.*, *\([0-9.]*\)%* id.*/\1/" | awk '{print 100 - $1}'
    
    echo -e "\nMemory Usage: "
    free | awk '/Mem/{printf("%.2f"), $3/$2*100}'
    
    echo -e "\nDisk Space: "
    df -h / | awk '/\//{print $(NF-1)}'
    
    echo -e "\nNetwork Statistics: "
    netstat -i
    
    echo -e "\nTop Processes: "
    top -bn1 | head -n 10
}

# Function to analyze logs
Log_Analysis() {
    echo -e "\nRecent Critical Events: "
    tail -n 200 /var/log/syslog | grep -iE 'error|critical'
    
    echo -e "\nRecent Logs: "
    tail -n 20 /var/log/syslog
}

# Function to perform health checks
Health_Check() {
    echo -e "\nService Status: "
    for service in "${SERVICE_STATUS[@]}"; do
        systemctl is-active --quiet "$service"
        if [ $? -eq 0 ]; then
            echo "   $service is running."
        else
            echo "   Alert: $service is not running."
        fi
    done
    
    echo -e "\nConnectivity Check: "
    for service in "${EXTERNAL_SERVICES[@]}"; do
        ping -c 1 "$service" >/dev/null 2>&1
        if [ $? -eq 0 ]; then
            echo "   Connectivity to $service is okay."
        else
            echo "   Alert: Unable to connect to $service."
        fi
    done
}

# Check CPU and Memory usage against thresholds
CPU_USAGE=$(top -bn1 | grep "Cpu(s)" | sed "s/.*, *\([0-9.]*\)%* id.*/\1/")
MEMORY_USAGE=$(free | awk '/Mem/{printf("%.2f"), $3/$2*100}')
if (( $(echo "$CPU_USAGE >= $ALERT_THRESHOLD_CPU" | bc -l) )); then
    echo "High CPU Usage Alert: $CPU_USAGE%"
fi
if (( $(echo "$MEMORY_USAGE >= $ALERT_THRESHOLD_MEM" | bc -l) )); then
    echo "High Memory Usage Alert: $MEMORY_USAGE%"
fi

# Create report directory and file
mkdir -p "$REPORTDIR"
REPORTFILE="$REPORTDIR/sysreport_$(date +'%Y-%m-%d_%H-%M-%S').txt"
{
    echo "System Report $(date)"
    System_Metrics
    Log_Analysis
    Health_Check
} > "$REPORTFILE"

# Interactive mode
echo "Select an option:
1. Check system metrics
2. View logs
3. Check service status
4. Exit"
read -r choice
case $choice in
    1) System_Metrics ;;
    2) Log_Analysis ;;
    3) Health_Check ;;
    4) exit ;;
    *) echo "Invalid option" ;;
esac

Grant Execute Permission to the Script

sh

chmod 755 system_monitor.sh

Run the Script

sh

./system_monitor.sh

After running the script, it will generate a report file containing details such as CPU usage, memory usage, disk space, and more.
Project 02: Deploying a Multi-Tier Application with a CI/CD Pipeline
Overview

Deploy a multi-tier application (frontend, backend, and database) using Docker Swarm and Kubernetes, ensuring data persistence with a shared volume across multiple containers, and automate the entire process using advanced shell scripting and CI/CD pipelines.
Step-by-Step Guide
1. Set up Docker Swarm and Create a Multi-Tier Service
Initialize Docker Swarm

sh

docker swarm init

Create a Multi-Tier Docker Swarm Service

Create a file named docker-compose-swarm.yml:

yaml

version: '3.7'
services:
  frontend:
    image: nginx
    ports:
      - "8082:80"
    deploy:
      replicas: 2
    volumes:
      - shareddata:/usr/share/nginx/html

  backend:
    image: hello-world
    ports:
      - "8081:80"
    deploy:
      replicas: 2
    volumes:
      - shareddata:/app/data

  db:
    image: postgres
    environment:
      POSTGRES_DB: mydb
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    deploy:
      replicas: 1
    volumes:
      - dbdata:/var/lib/postgresql/data

volumes:
  shareddata:
  dbdata:

Deploy the Stack Using Docker Swarm

sh

docker stack deploy -c docker-compose-swarm.yml myapp

CI/CD Pipeline with Jenkins
Step 1: Setup Jenkins Project

    Log in to Jenkins.
    From the dashboard, create a new project and select "Freestyle project".
    Enter a name for the project and click "OK".

Step 2: Configure Source Code Management

    In the project configuration, go to "Source Code Management".
    Select "Git" and add your repository URL.
    Ensure your repository is public or provide credentials if private.
    Specify the branch to use.

Step 3: Set up Build Triggers

    In the "Build Triggers" section, select "Build periodically".
    Add the following cron expression to trigger the build every 5 minutes:

sh

*/5 * * * *

Step 4: Save and Run